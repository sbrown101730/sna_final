---
title: "funny_centralities"
author: "Siya Brown"
date: today 
format: html
editor_options: 
  chunk_output_type: console
---

```{r}
#| echo: true
#| output: false
#| message: false
#| label: load packages

# Start with a clear environment
rm(list=ls())

######################################################################################
# The first time you run this file, you will need to install several packages.
# To do that, run the code section below. It may take a couple minutes.
# You only need to install packages once, next time you should skip the install lines.
list.of.packages <- c("robustbase","igraph","statnet", "kableExtra", "poweRlaw")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)

# You need to load packages every time you run the script or restart R.
library(dplyr)
library(igraph)
library(ggplot2)
library(poweRlaw)
library(igraph)
library(tidyverse)
library(network)
# To chenetwork# To check whether your R loads these packages, run the following code
sessionInfo() ## check other attached packages. If igraph is listed there, you're ready!
```

```{r}
#| echo: false
#| output: false
#| message: false

rm(list=ls())

# Clear your environment
rm(list=ls())

# Install packages below if you do not have them:
# -------------------------------------------------
if (!"statnet" %in% installed.packages()) install.packages("statnet") # For fitting ERGMs
if (!"igraph" %in% installed.packages()) install.packages("igraph") # For network plotting
if (!"texreg" %in% installed.packages()) install.packages("texreg") # For printing "nicer" model output

library(statnet)
library(readr)

# -------------------------------------------------------------------------------------------------
# Set the working directory
# Session > Set Working Directory > To Source File Location
# -------------------------------------------------------------------------------------------------
list.files() # List the files in the current working directory to see if you're in the right directory

```

```{r}
#| echo: false
#| output: false
#| message: false
#| label: load data

hyperlink_large <- read_tsv("data/soc-redditHyperlinks-body.tsv") %>%
  janitor::clean_names() %>%
  select(source_subreddit, target_subreddit)

# read csv
popularity_large <- read_csv("data/subreddits_public.csv")

popularity_clean <- popularity_large %>%
  mutate(subreddit_name = str_to_lower(subreddit_name))

funny_1 <- hyperlink_large %>%
  janitor::clean_names() %>%
  filter(source_subreddit == "funny" | target_subreddit == "funny")
  
funny_2 <- hyperlink_large %>%
  janitor::clean_names() %>%
  filter(source_subreddit %in% funny_1$source_subreddit | 
           target_subreddit %in% funny_1$target_subreddit |
           source_subreddit %in% funny_1$target_subreddit |
           target_subreddit %in% funny_1$source_subreddit)
  
funny_3 <- funny_2 %>%
  count(source_subreddit, target_subreddit) %>%
  filter(n > 35)

popularity <- popularity_clean %>%
  filter(subreddit_name %in% funny_3$source_subreddit | 
           subreddit_name %in% funny_3$target_subreddit) %>%
  select(subreddit_name, subscribers_count) %>%
  mutate(
    subscribers_count = as.numeric(subscribers_count),
    size = case_when(
      subscribers_count <= 10000 ~ "small",
      subscribers_count <= 50000 ~ "medium",
      subscribers_count > 50000 ~ "large"
    ),
    size = size %>% 
      replace_na("missing")
  ) %>% 
  arrange(subreddit_name)

summary(popularity)
```

```{r}
#| message: false
#| warning: false
#| label: centrality
######################################################################################
#
# Part III: Local Network Properties
#
######################################################################################

# For this part, you switch 'igraph' to 'sna' package because we are going to use 
# some functions that only are available in sna package
# As a first step, create a 'sna' graph object from an 'igraph' object

# Convert funny_3 into an igraph object
funny3_igraph <- igraph::graph_from_data_frame(funny_3, directed = TRUE)

# As a first step, create a 'sna' graph object from an 'igraph' object
sna_funny3 <-
  igraph::as_adjacency_matrix(funny3_igraph, sparse = FALSE) %>% network::as.network.matrix()

# this detaching is a necessary step since the two packages have some same function names
# R is often confused
library(igraph)

# We will compute centralities based on 'network' package
# First, create a dataframe to store the centrality information
centralities_funny3 <- data.frame('node_name' = as.character(network.vertex.names(sna_funny3)))
```

### degree
# For directed graphs, we can calculate in-degree, out-degree, and total degree centralities separately:

```{r}
#| label: degree
# Calculate in-degree centrality (number of incoming edges)
centralities_funny3$in_degree <- degree(funny3_igraph, mode = "in")

# Calculate out-degree centrality (number of outgoing edges)
centralities_funny3$out_degree <- degree(funny3_igraph, mode = "out")

# Calculate total degree centrality (sum of in-degree and out-degree)
centralities_funny3$total_degree <- degree(funny3_igraph, mode = "all")

# Display the top 10 nodes by in-degree
centralities_funny3 |> 
  dplyr::slice_max(order_by = in_degree, n = 10) |> 
  select(node_name, in_degree) |> 
  kableExtra::kable()

# Display the top 10 nodes by out-degree
centralities_funny3 |> 
  dplyr::slice_max(order_by = out_degree, n = 10) |> 
  select(node_name, out_degree) |> 
  kableExtra::kable()

# Display the top 10 nodes by total degree
centralities_funny3 |> 
  dplyr::slice_max(order_by = total_degree, n = 10) |> 
  select(node_name, total_degree) |> 
  kableExtra::kable()

```

### betweenness

```{r}
#| label: betweenness
# Calculate betweenness centrality and store it in the data.frame called 'centralities'
centralities_funny3$betweenness <- betweenness(funny3_igraph, directed = TRUE)

# Top 10 nodes by betweenness centrality
centralities_funny3 |> 
  dplyr::slice_max(order_by = betweenness, n = 10) |> 
  select(node_name, betweenness) |> 
  kableExtra::kable()
```

### closeness # this is calculating outgoing paths

```{r}
#| label: closeness
#| 
centralities_funny3$closeness <- closeness(funny3_igraph, mode = "out")

# Top 10 nodes by closeness centrality
centralities_funny3 |> 
  dplyr::slice_max(order_by = closeness, n = 10) |> 
  select(node_name, closeness) |> 
  kableExtra::kable()

```

### eigenvector

```{r}
#| label: eigenvector
# Calculate eigenvector centrality and store it in the data.frame called 'centralities'
# using 'igraph' because the code implemented in 'sna' is unreliable

centralities_funny3$eigenvector <- eigen_centrality(funny3_igraph, directed = TRUE)$vector

# Top 10 nodes by eigenvector centrality
centralities_funny3 |> 
  dplyr::slice_max(order_by = eigenvector, n = 10) |> 
  select(node_name, eigenvector) |> 
  kableExtra::kable()


```

### Burt's network constraint

```{r}
#| label: burt
# Calculate Burt's network constraint and store it in the data.frame called 'centralities'
# using 'igraph' because 'sna' doesn't have the function
centralities_funny3$netconstraint <- igraph::constraint(funny3_igraph)
# help(constraint) # Be careful with the interpretation for constraint: High constraint = redundant contacts, low constraint = acting as a broker

centralities_funny3 |> 
  dplyr::slice_min(order_by = netconstraint, n = 10) %>%
  select(node_name, netconstraint) %>%
  kableExtra::kable()

```

### K-core

```{r}
#| message: false
#| warning: false
#| label: k-core 1
######################################################################################
#
# Part IV: Global Network Properties
#
######################################################################################
# To go back to igraph analysis, don't forget detaching 'sna' and 'network' first
# before recalling 'igraph'
detach('package:statnet', unload = TRUE)
library(igraph)

## calculate k-cores
kcore_funny3 <-
  funny3_igraph %>% coreness(.)
kcore_funny3 ## show the results of k-core decomposition

```

```{r}
#| label: k-core 2
## Plot a graph colored by the k-core decomposition results
funny3_igraph %>%
  plot(
    .,
    layout = layout_with_gem(.),
    # layout = layout_with_sugiyama(.),
    edge.arrow.size = .3,
    vertex.size = 20,
    vertex.label = V(funny3_igraph)$name,
    vertex.color = adjustcolor(graph.coreness(.), alpha.f = .3),
    vertex.label.cex = .5,
    vertex.label.color = 'black',
    mark.groups = by(seq_along(graph.coreness(.)), graph.coreness(.), invisible),
    mark.shape = 1 / 4,
    mark.col = rainbow(length(unique(graph.coreness(
      .
    ))), alpha = .1),
    mark.border = NA,
  )

```

```{r}
#| label: community detection
# Plot the number of clusters in the graph and their size
# there are also other algorithms for this you may want to explore
# below is using Newman-Girvan Algorithm (2003)
# if communities do not make sense to you, replace with your choice
# e.g., cluster_infomap, cluster_walktrap etc.
cluster_funny3 <- funny3_igraph %>% cluster_edge_betweenness()
# cluster_hmn <- giantGraph_hmn %>% cluster_edge_betweenness()
## you may see orange warning messages since the edge betweenness algorithm is not designed for a directed graph
## but you'll be able to see the results anyway.
## if you want to use a more appropriate algorithm for a directed graph, try:
# cluster <- giantGraph_gpt %>% cluster_walktrap()
# cluster <- giantGraph_hmn %>% cluster_walktrap()

```

```{r}
#| label: community detection 2
# Find the number of clusters
membership(cluster_funny3)   # affiliation list
# membership(cluster_hmn)   # affiliation list
length(cluster_funny3) # number of clusters
# length(cluster_hmn) # number of clusters

# Find the size of each cluster
# Note that communities with one node are isolates, or have only a single tie
sizes(cluster_funny3)
# sizes(cluster_hmn) 
```

```{r}
#| label: modularity
# modularity measure
modularity(cluster_funny3)
# modularity(cluster_hmn)
```

Interpret the modularity score of your results of community detection.

The modularity score is 0.6327548. Modularity is an assessment of the number of connections within a cluster and the comparison of how many connections would exist in a randomly distributed network. This modularity score means that the network has a relatively high level of community structure. Specifically, a modularity score of 0.6327548 indicates that the subreddits within each detected community are more densely interconnected with each other than with subreddits outside their community. 

In practical terms, this suggests that the communities identified in the **r/funny** network are well-defined, with many links within each community and fewer links between communities. Such a high modularity score often implies that the network is composed of distinct groups or clusters, where members within each group are more closely related or interact more frequently than they do with members of other groups. This could reflect different thematic focuses, user bases, or interaction patterns among the subreddits in the network.

In summary, the high modularity score indicates that the community detection algorithm has successfully identified cohesive groups within the network, revealing meaningful subgroups of subreddits that are more internally connected than they are with the rest of the network.

```{r}
#| label: community detection 3
# Visualize clusters - that puts colored blobs around the nodes in the same community.
# You may want to remove vertex.label=NA to figure out what terms are clustered.
cluster_funny3 %>% plot(
  .,
  funny3_igraph,
  #layout = layout_nicely(giantGraph_gpt),
  layout = layout_with_fr(funny3_igraph),
  edge.arrow.size = .3,
  vertex.size = 10,
  vertex.label = V(funny3_igraph)$name,
  vertex.color = adjustcolor(membership(.), alpha.f = .3),
  vertex.label.cex = .3,
  vertex.label.color = 'black',
  mark.groups = by(seq_along(membership(.)), membership(.), invisible),
  mark.shape = 1/4,
  mark.col = rainbow(length(.), alpha = .1),
  mark.border = NA
)

```

