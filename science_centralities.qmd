---
title: "science_centralities"
author: "Siya Brown"
date: today 
format: html
editor_options: 
  chunk_output_type: console
---

```{r}
#| echo: true
#| output: false
#| message: false
#| label: load packages

# Start with a clear environment
rm(list=ls())

######################################################################################
# The first time you run this file, you will need to install several packages.
# To do that, run the code section below. It may take a couple minutes.
# You only need to install packages once, next time you should skip the install lines.
list.of.packages <- c("robustbase","igraph","statnet", "kableExtra", "poweRlaw")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)

# You need to load packages every time you run the script or restart R.
library(dplyr)
library(igraph)
library(ggplot2)
library(poweRlaw)
library(igraph)
library(tidyverse)
library(network)
# To chenetwork# To check whether your R loads these packages, run the following code
sessionInfo() ## check other attached packages. If igraph is listed there, you're ready!
```

```{r}
#| echo: false
#| output: false
#| message: false

rm(list=ls())

# Clear your environment
rm(list=ls())

# Install packages below if you do not have them:
# -------------------------------------------------
if (!"statnet" %in% installed.packages()) install.packages("statnet") # For fitting ERGMs
if (!"igraph" %in% installed.packages()) install.packages("igraph") # For network plotting
if (!"texreg" %in% installed.packages()) install.packages("texreg") # For printing "nicer" model output

library(statnet)
library(readr)

# -------------------------------------------------------------------------------------------------
# Set the working directory
# Session > Set Working Directory > To Source File Location
# -------------------------------------------------------------------------------------------------
list.files() # List the files in the current working directory to see if you're in the right directory

```

```{r}
#| echo: false
#| output: false
#| message: false
#| label: load data

hyperlink_large <- read_tsv("data/soc-redditHyperlinks-body.tsv") %>%
  janitor::clean_names() %>%
  select(source_subreddit, target_subreddit)

# read csv
popularity_large <- read_csv("data/subreddits_public.csv")

popularity_clean <- popularity_large %>%
  mutate(subreddit_name = str_to_lower(subreddit_name))

science_1 <- hyperlink_large %>%
  janitor::clean_names() %>%
  filter(source_subreddit == "science" | target_subreddit == "science")
  
science_2 <- hyperlink_large %>%
  janitor::clean_names() %>%
  filter(source_subreddit %in% science_1$source_subreddit | 
           target_subreddit %in% science_1$target_subreddit |
           source_subreddit %in% science_1$target_subreddit |
           target_subreddit %in% science_1$source_subreddit)
  
science_3 <- science_2 %>%
  count(source_subreddit, target_subreddit) %>%
  filter(n > 35)

popularity <- popularity_clean %>%
  filter(subreddit_name %in% science_3$source_subreddit | 
           subreddit_name %in% science_3$target_subreddit) %>%
  select(subreddit_name, subscribers_count) %>%
  mutate(
    subscribers_count = as.numeric(subscribers_count),
    size = case_when(
      subscribers_count <= 10000 ~ "small",
      subscribers_count <= 50000 ~ "medium",
      subscribers_count > 50000 ~ "large"
    ),
    size = size %>% 
      replace_na("missing")
  ) %>% 
  arrange(subreddit_name)

summary(popularity)
```

```{r}
#| message: false
#| warning: false
#| label: centrality
######################################################################################
#
# Part III: Local Network Properties
#
######################################################################################

# For this part, you switch 'igraph' to 'sna' package because we are going to use 
# some functions that only are available in sna package
# As a first step, create a 'sna' graph object from an 'igraph' object

# Convert science_3 into an igraph object
science3_igraph <- igraph::graph_from_data_frame(science_3, directed = TRUE)

# As a first step, create a 'sna' graph object from an 'igraph' object
sna_science3 <-
  igraph::as_adjacency_matrix(science3_igraph, sparse = FALSE) %>% network::as.network.matrix()

# this detaching is a necessary step since the two packages have some same function names
# R is often confused
library(igraph)
```

## giant component 

```{r}
# Find the components
science_comp <- igraph::components(science3_igraph)

# Extract the largest connected component
giantGraph_science <- induced_subgraph(science3_igraph, which(science_comp$membership == which.max(science_comp$csize)))

# Verify the size of the largest component
vcount(giantGraph_science) # number of nodes
ecount(giantGraph_science) # number of edges


# We will compute centralities based on 'network' package
# First, create a dataframe to store the centrality information
centralities_giantGraph_science <- data.frame('node_name' = V(giantGraph_science)$name)
```


### degree
# For directed graphs, we can calculate in-degree, out-degree, and total degree centralities separately:

```{r}
#| label: Degree Centralities 

library(igraph)
# Calculate in-degree centrality (number of incoming edges)
V(giantGraph_science)$in_degree <- igraph::degree(giantGraph_science, mode = "in")

# Calculate out-degree centrality (number of outgoing edges)
V(giantGraph_science)$out_degree <- igraph::degree(giantGraph_science, mode = "out")

# Calculate total degree centrality (sum of in-degree and out-degree)
V(giantGraph_science)$total_degree <- igraph::degree(giantGraph_science, mode = "all")

# Display the top 10 nodes by in-degree
top_in_degree <- data.frame(node_name = V(giantGraph_science)$name, in_degree = V(giantGraph_science)$in_degree) |> 
  dplyr::slice_max(order_by = in_degree, n = 10) |> 
  kableExtra::kable()
top_in_degree

# Display the top 10 nodes by out-degree
top_out_degree <- data.frame(node_name = V(giantGraph_science)$name, out_degree = V(giantGraph_science)$out_degree) |> 
  dplyr::slice_max(order_by = out_degree, n = 10) |> 
  kableExtra::kable()
top_out_degree

# Display the top 10 nodes by total degree
top_total_degree <- data.frame(node_name = V(giantGraph_science)$name, total_degree = V(giantGraph_science)$total_degree) |> 
  dplyr::slice_max(order_by = total_degree, n = 10) |> 
  kableExtra::kable()
top_total_degree
```

### betweenness

```{r}
#| label: betweenness

V(giantGraph_science)$betweenness <- igraph::betweenness(giantGraph_science, directed = TRUE)

# Top 10 nodes by betweenness centrality
top_betweenness <- data.frame(node_name = V(giantGraph_science)$name, betweenness = V(giantGraph_science)$betweenness) |> 
  dplyr::slice_max(order_by = betweenness, n = 10) |> 
  kableExtra::kable()
top_betweenness

```

### closeness # this is calculating outgoing paths

```{r}
#| label: closeness
### Closeness Centrality ###
V(giantGraph_science)$closeness <- igraph::closeness(giantGraph_science, mode = "out")

# Top 10 nodes by closeness centrality
top_closeness <- data.frame(node_name = V(giantGraph_science)$name, closeness = V(giantGraph_science)$closeness) |> 
  dplyr::slice_max(order_by = closeness, n = 10) |> 
  kableExtra::kable()
top_closeness

```

### eigenvector

```{r}
#| label: eigenvector
# Calculate eigenvector centrality and store it in the data.frame called 'centralities'
# using 'igraph' because the code implemented in 'sna' is unreliable


### Eigenvector Centrality ###
V(giantGraph_science)$eigenvector <- igraph::eigen_centrality(giantGraph_science, directed = TRUE)$vector

# Top 10 nodes by eigenvector centrality
top_eigenvector <- data.frame(node_name = V(giantGraph_science)$name, eigenvector = V(giantGraph_science)$eigenvector) |> 
  dplyr::slice_max(order_by = eigenvector, n = 10) |> 
  kableExtra::kable()
top_eigenvector


```

### Burt's network constraint

```{r}
#| label: burt
# Calculate Burt's network constraint and store it in the data.frame called 'centralities'
# using 'igraph' because 'sna' doesn't have the function
centralities_giantGraph_science$netconstraint <- igraph::constraint(giantGraph_science)
# help(constraint) # Be careful with the interpretation for constraint: High constraint = redundant contacts, low constraint = acting as a broker

centralities_giantGraph_science |> 
  dplyr::slice_min(order_by = netconstraint, n = 10) %>%
  select(node_name, netconstraint) %>%
  kableExtra::kable()

```

### K-core

```{r}
#| message: false
#| warning: false
#| label: k-core 1
######################################################################################
#
# Part IV: Global Network Properties
#
######################################################################################
# To go back to igraph analysis, don't forget detaching 'sna' and 'network' first
# before recalling 'igraph'
detach('package:statnet', unload = TRUE)
library(igraph)

## calculate k-cores
kcore_science <-
  giantGraph_science %>% coreness(.)
kcore_science ## show the results of k-core decomposition

```

```{r}
#| label: k-core 2
## Plot a graph colored by the k-core decomposition results
giantGraph_science %>%
  plot(
    .,
    layout = layout_with_gem(.),
    # layout = layout_with_sugiyama(.),
    edge.arrow.size = .3,
    vertex.size = 20,
    vertex.label = V(giantGraph_science)$name,
    vertex.color = adjustcolor(graph.coreness(.), alpha.f = .3),
    vertex.label.cex = .5,
    vertex.label.color = 'black',
    mark.groups = by(seq_along(graph.coreness(.)), graph.coreness(.), invisible),
    mark.shape = 1 / 4,
    mark.col = rainbow(length(unique(graph.coreness(
      .
    ))), alpha = .1),
    mark.border = NA,
  )

```

```{r}
#| label: community detection
# Plot the number of clusters in the graph and their size
# there are also other algorithms for this you may want to explore
# below is using Newman-Girvan Algorithm (2003)
# if communities do not make sense to you, replace with your choice
# e.g., cluster_infomap, cluster_walktrap etc.
cluster_science <- giantGraph_science %>% cluster_edge_betweenness()
# cluster_hmn <- giantGraph_hmn %>% cluster_edge_betweenness()
## you may see orange warning messages since the edge betweenness algorithm is not designed for a directed graph
## but you'll be able to see the results anyway.
## if you want to use a more appropriate algorithm for a directed graph, try:
# cluster <- giantGraph_gpt %>% cluster_walktrap()
# cluster <- giantGraph_hmn %>% cluster_walktrap()

```

```{r}
#| label: community detection 2
# Find the number of clusters
membership(cluster_science)   # affiliation list
# membership(cluster_hmn)   # affiliation list
length(cluster_science) # number of clusters
# length(cluster_hmn) # number of clusters

# Find the size of each cluster
# Note that communities with one node are isolates, or have only a single tie
sizes(cluster_science)
# sizes(cluster_hmn) 
```

```{r}
#| label: modularity
# modularity measure
modularity(cluster_science)
# modularity(cluster_hmn)
```

Interpret the modularity score of your results of community detection.

The modularity score is 0.2335753. Modularity is an assessment of the number of connections within a cluster and the comparison of how many connections would exist in a randomly distributed network. This modularity score means that the network ......

```{r}
#| label: community detection 3
# Visualize clusters - that puts colored blobs around the nodes in the same community.
# You may want to remove vertex.label=NA to figure out what terms are clustered.
cluster_science %>% plot(
  .,
  giantGraph_science,
  #layout = layout_nicely(giantGraph_gpt),
  layout = layout_with_fr(giantGraph_science),
  edge.arrow.size = .3,
  vertex.size = 10,
  vertex.label = V(science3_igraph)$name,
  vertex.color = adjustcolor(membership(.), alpha.f = .3),
  vertex.label.cex = .3,
  vertex.label.color = 'black',
  mark.groups = by(seq_along(membership(.)), membership(.), invisible),
  mark.shape = 1/4,
  mark.col = rainbow(length(.), alpha = .1),
  mark.border = NA
)

```